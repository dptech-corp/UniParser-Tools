{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb22fdb",
   "metadata": {},
   "source": [
    "本教程介绍UniParser Tools的基础用法，包括如何使用它来解析多种文件和格式化文本数据。\n",
    "\n",
    "本文以 40001 端口提供的UniParser服务为例进行演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04133361",
   "metadata": {},
   "source": [
    "## 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca4caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from uniparser_tools.api.clients import UniParserClient\n",
    "from uniparser_tools.common.constant import FormatFlag, ParseMode, ParseModeTextual\n",
    "from uniparser_tools.utils.convert import dict2obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448421d5",
   "metadata": {},
   "source": [
    "## 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a98b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前有多个可用host开启，但是不同host对应功能不完全相同，解析质量也不一样\n",
    "# 具体请在售后群中咨询相关的的host信息和功能\n",
    "# 使用时请勿并发数量过大，公开Uni-Parser服务最高仅允许5并发\n",
    "\n",
    "UNIPARSER_PRIVATE_IP = os.getenv('UNIPARSER_PRIVATE_IP')\n",
    "host = f\"http://{UNIPARSER_PRIVATE_IP}:40001\"  # 火山云内网\n",
    "# host = f\"http://{UNIPARSER_PUBLIC_IP}:40001\"  # 外网\n",
    "\n",
    "# 替换为你的用户名, 目前不需要认证，只是一个标识，后续需要填写api key等认证信息\n",
    "user = \"admin\" # 用于生成token，务必修改，使用默认user可能会与其他用户导致任务重复\n",
    "\n",
    "# 初始化客户端\n",
    "parser = UniParserClient(user=user, host=host)\n",
    "\n",
    "# 创建一个目录来保存解析结果\n",
    "save_dir = \"./outputs/quick_start\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14529b4",
   "metadata": {},
   "source": [
    "## 1. PDF文件解析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74367e2e",
   "metadata": {},
   "source": [
    "### 提交解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a2ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置解析文件路径\n",
    "pdf_path = \"./tasks/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\"\n",
    "\n",
    "# 提交解析任务\n",
    "trigger_file_result = parser.trigger_file(\n",
    "    pdf_path,\n",
    "    textual=ParseModeTextual.DigitalExported,\n",
    "    table=ParseMode.OCRFast,\n",
    "    molecule=ParseMode.OCRFast,\n",
    "    chart=ParseMode.DumpBase64,\n",
    "    figure=ParseMode.DumpBase64,\n",
    "    expression=ParseMode.DumpBase64,\n",
    "    equation=ParseMode.OCRFast,\n",
    ")\n",
    "if trigger_file_result[\"status\"] != \"success\":\n",
    "    print(json.dumps(trigger_file_result, indent=4))\n",
    "    raise Exception(\"trigger file failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e49ab2",
   "metadata": {},
   "source": [
    "### 获取结果\n",
    "> 可以持有token多次进行获取\n",
    "> \n",
    "> 可获取不同格式数据以供不用的场景使用\n",
    ">\n",
    "> formatted 只对objects和content产生作用，pages_dict和pages_tree不受影响"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9878a662",
   "metadata": {},
   "source": [
    "#### - Content (End2End) 格式输出\n",
    "> 主要用于获取解析后的文本内容，返回内容为str格式的全文内容，可以用于LLM等场景\n",
    "> \n",
    "> 在同一次格式化输出中，可以设置不同语义的输出模式，例如表格使用HTML进行输出，公式使用LaTeX进行输出，文本使用Markdown进行输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cf9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务提交成功后，会返回一个token，用于获取解析结果\n",
    "assert trigger_file_result[\"status\"] == \"success\"\n",
    "token = trigger_file_result[\"token\"]\n",
    "for formatted in list(FormatFlag)[1:]:\n",
    "    # content must be True\n",
    "    # formatted 只对objects和content产生作用，pages_dict和pages_tree不受影响\n",
    "    result = parser.get_formatted(\n",
    "        token,\n",
    "        content=True,\n",
    "        objects=False,\n",
    "        pages_dict=False,\n",
    "        pages_tree=False,\n",
    "        molecule_source=False,\n",
    "        textual=formatted,\n",
    "        chart=formatted,\n",
    "        table=formatted,\n",
    "        molecule=formatted,\n",
    "        equation=formatted,\n",
    "        figure=formatted,\n",
    "        expression=formatted,\n",
    "    )\n",
    "    if result[\"status\"] != \"success\":\n",
    "        print(f\"Get formatted failed for {formatted}, results is: {json.dumps(result, indent=4)}\")\n",
    "        continue\n",
    "\n",
    "    head, tail = \"\", \"\"\n",
    "    suffix = \"\"\n",
    "    if formatted == \"latex\":\n",
    "        head = \"\\documentclass{article}\\n\\n\\\\usepackage{booktabs}\\n\\n\\\\begin{document}\\n\"\n",
    "        tail = \"\\end{document}\"\n",
    "        suffix = \"tex\"\n",
    "    elif formatted == \"html\":\n",
    "        head = \"<html>\\n\\n<body>\\n\"\n",
    "        tail = \"</body>\\n\\n</html>\"\n",
    "        suffix = \"html\"\n",
    "    elif formatted == \"markdown\":\n",
    "        suffix = \"md\"\n",
    "    elif formatted == \"plain\":\n",
    "        suffix = \"plain\"\n",
    "    elif formatted == \"markup\":\n",
    "        suffix = \"txt\"\n",
    "    else:\n",
    "        print(f\"Unknown format: {formatted}\")\n",
    "        continue\n",
    "\n",
    "    with open(f\"{save_dir}/{token}.{suffix}\", \"w\") as f:\n",
    "        if head:\n",
    "            f.write(head + \"\\n\")\n",
    "        try:\n",
    "            f.write(result[\"content\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "        if tail:\n",
    "            f.write(tail + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34154723",
   "metadata": {},
   "source": [
    "#### - Objects 格式输出\n",
    "> 主要用于获取解析后的语义块，返回内容为json格式的全文语义块，可以用于后续的语义分析等场景\n",
    "> \n",
    "> 目前主要用于Uni-Miner标注平台等场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d545817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert trigger_file_result[\"status\"] == \"success\"\n",
    "token = trigger_file_result[\"token\"]\n",
    "formatted = FormatFlag.Markup\n",
    "result = parser.get_formatted(\n",
    "    token,\n",
    "    content=False,\n",
    "    objects=True,\n",
    "    pages_dict=False,\n",
    "    pages_tree=False,\n",
    "    molecule_source=False,\n",
    "    textual=formatted,\n",
    "    chart=formatted,\n",
    "    table=formatted,\n",
    "    molecule=formatted,\n",
    "    equation=formatted,\n",
    "    figure=formatted,\n",
    "    expression=formatted,\n",
    ")\n",
    "if result[\"status\"] != \"success\":\n",
    "    print(f\"Get formatted failed for {formatted}, results is: {json.dumps(result, indent=4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d53f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'title',\n",
       "  'confidence': 0.82763671875,\n",
       "  'float_xyxy': [0.24719669616300297,\n",
       "   0.13417969327984433,\n",
       "   0.7203585057476767,\n",
       "   0.15253907020645913],\n",
       "  'page': 0,\n",
       "  'str': '\\\\begin{title}\\nDeep Residual Learning for Image Recognition\\n\\\\end{title}\\n'},\n",
       " {'class': 'paragraph',\n",
       "  'confidence': 0.59619140625,\n",
       "  'float_xyxy': [0.21939338733947356,\n",
       "   0.19199219135322956,\n",
       "   0.750183853448606,\n",
       "   0.24765627311937738],\n",
       "  'page': 0,\n",
       "  'str': 'Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun Microsoft Research {kahe, v-xiangz, v-shren, jiansun}@microsoft.com\\n'},\n",
       " {'class': 'title',\n",
       "  'confidence': 0.8115234375,\n",
       "  'float_xyxy': [0.23531710556130003,\n",
       "   0.28457032791291825,\n",
       "   0.310638801724303,\n",
       "   0.2974609606193774],\n",
       "  'page': 0,\n",
       "  'str': '\\\\begin{title}\\nAbstract\\n\\\\end{title}\\n'},\n",
       " {'class': 'paragraph',\n",
       "  'confidence': 0.97802734375,\n",
       "  'float_xyxy': [0.0792394338869581,\n",
       "   0.31132813655968866,\n",
       "   0.4676011528065002,\n",
       "   0.5347656481193773],\n",
       "  'page': 0,\n",
       "  'str': 'Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.\\n'},\n",
       " {'class': 'paragraph',\n",
       "  'confidence': 0.96923828125,\n",
       "  'float_xyxy': [0.07734375373989928,\n",
       "   0.5375000154129183,\n",
       "   0.4681066375931883,\n",
       "   0.65625],\n",
       "  'page': 0,\n",
       "  'str': 'The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28% relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.\\n'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"objects\"][:5]  # 全文的前5个语义块（所有页面合并）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b20d71",
   "metadata": {},
   "source": [
    "#### - Pages dict 格式输出\n",
    "> Uni-Parser 的原始解析格式之一，未经过任何format化，返回内容为json格式的全文语义块，可以用于后续的语义分析等场景\n",
    "> \n",
    "> 内容详尽充分，但是格式较为复杂，需要自行解析，可以自行 重排序 、去重 等操作，是高阶玩法必备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5e44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert trigger_file_result[\"status\"] == \"success\"\n",
    "token = trigger_file_result[\"token\"]\n",
    "formatted = FormatFlag.Plain\n",
    "result = parser.get_formatted(\n",
    "    token,\n",
    "    content=False,\n",
    "    objects=False,\n",
    "    pages_dict=True,\n",
    "    pages_tree=False,\n",
    "    molecule_source=False,\n",
    "    textual=formatted,\n",
    "    chart=formatted,\n",
    "    table=formatted,\n",
    "    molecule=formatted,\n",
    "    equation=formatted,\n",
    "    figure=formatted,\n",
    "    expression=formatted,\n",
    ")\n",
    "if result[\"status\"] != \"success\":\n",
    "    print(f\"Get formatted failed for {formatted}, results is: {json.dumps(result, indent=4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f837f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': '1a8888ee3e50585db98952c72834498e',\n",
       "  'page': 0,\n",
       "  'block': 11,\n",
       "  'bbox': {'x1': 0.24719669616300297,\n",
       "   'y1': 0.13417969327984433,\n",
       "   'x2': 0.7203585057476767,\n",
       "   'y2': 0.15253907020645913},\n",
       "  'conf': 0.82763671875,\n",
       "  'page_size': [1224, 1584],\n",
       "  'type': 'title',\n",
       "  'hidden': False,\n",
       "  'order': 0,\n",
       "  'lang': 'en',\n",
       "  'direction': -1,\n",
       "  'source': '',\n",
       "  'bboxes': [],\n",
       "  'contents': [],\n",
       "  'text': 'Deep Residual Learning for Image Recognition'},\n",
       " {'token': '1a8888ee3e50585db98952c72834498e',\n",
       "  'page': 0,\n",
       "  'block': 10,\n",
       "  'bbox': {'x1': 0.21939338733947356,\n",
       "   'y1': 0.19199219135322956,\n",
       "   'x2': 0.750183853448606,\n",
       "   'y2': 0.24765627311937738},\n",
       "  'conf': 0.59619140625,\n",
       "  'page_size': [1224, 1584],\n",
       "  'type': 'paragraph',\n",
       "  'hidden': False,\n",
       "  'order': 1,\n",
       "  'lang': 'en',\n",
       "  'direction': -1,\n",
       "  'source': '',\n",
       "  'bboxes': [],\n",
       "  'contents': [],\n",
       "  'text': 'Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun Microsoft Research {kahe, v-xiangz, v-shren, jiansun}@microsoft.com'},\n",
       " {'token': '1a8888ee3e50585db98952c72834498e',\n",
       "  'page': 0,\n",
       "  'block': 13,\n",
       "  'bbox': {'x1': 0.23531710556130003,\n",
       "   'y1': 0.28457032791291825,\n",
       "   'x2': 0.310638801724303,\n",
       "   'y2': 0.2974609606193774},\n",
       "  'conf': 0.8115234375,\n",
       "  'page_size': [1224, 1584],\n",
       "  'type': 'title',\n",
       "  'hidden': False,\n",
       "  'order': 2,\n",
       "  'lang': 'en',\n",
       "  'direction': -1,\n",
       "  'source': '',\n",
       "  'bboxes': [],\n",
       "  'contents': [],\n",
       "  'text': 'Abstract'},\n",
       " {'token': '1a8888ee3e50585db98952c72834498e',\n",
       "  'page': 0,\n",
       "  'block': 3,\n",
       "  'bbox': {'x1': 0.0792394338869581,\n",
       "   'y1': 0.31132813655968866,\n",
       "   'x2': 0.4676011528065002,\n",
       "   'y2': 0.5347656481193773},\n",
       "  'conf': 0.97802734375,\n",
       "  'page_size': [1224, 1584],\n",
       "  'type': 'paragraph',\n",
       "  'hidden': False,\n",
       "  'order': 3,\n",
       "  'lang': 'en',\n",
       "  'direction': -1,\n",
       "  'source': '',\n",
       "  'bboxes': [],\n",
       "  'contents': [],\n",
       "  'text': 'Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.'},\n",
       " {'token': '1a8888ee3e50585db98952c72834498e',\n",
       "  'page': 0,\n",
       "  'block': 7,\n",
       "  'bbox': {'x1': 0.07734375373989928,\n",
       "   'y1': 0.5375000154129183,\n",
       "   'x2': 0.4681066375931883,\n",
       "   'y2': 0.65625},\n",
       "  'conf': 0.96923828125,\n",
       "  'page_size': [1224, 1584],\n",
       "  'type': 'paragraph',\n",
       "  'hidden': False,\n",
       "  'order': 4,\n",
       "  'lang': 'en',\n",
       "  'direction': -1,\n",
       "  'source': '',\n",
       "  'bboxes': [],\n",
       "  'contents': [],\n",
       "  'text': 'The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28% relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"pages_dict\"][0][:5]  # 第一个页面的前5个语义块 (按照页面进行了拆分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "877ba504",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_dict = dict2obj(result[\"pages_dict\"])  # 可以将pages_dict转换为对象，方便后续操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "074956b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextualResult(token='1a8888ee3e50585db98952c72834498e', page=0, block=11, bbox=BBox(x1=0.24719669616300297, y1=0.13417969327984433, x2=0.7203585057476767, y2=0.15253907020645913), conf=0.82763671875, page_size=[1224, 1584], type='title', hidden=False, order=0, lang='en', direction=<Direction.Normal: -1>, source='', bboxes=[], contents=[], text='Deep Residual Learning for Image Recognition'),\n",
       " TextualResult(token='1a8888ee3e50585db98952c72834498e', page=0, block=10, bbox=BBox(x1=0.21939338733947356, y1=0.19199219135322956, x2=0.750183853448606, y2=0.24765627311937738), conf=0.59619140625, page_size=[1224, 1584], type='paragraph', hidden=False, order=1, lang='en', direction=<Direction.Normal: -1>, source='', bboxes=[], contents=[], text='Kaiming He Xiangyu Zhang Shaoqing Ren Jian Sun Microsoft Research {kahe, v-xiangz, v-shren, jiansun}@microsoft.com'),\n",
       " TextualResult(token='1a8888ee3e50585db98952c72834498e', page=0, block=13, bbox=BBox(x1=0.23531710556130003, y1=0.28457032791291825, x2=0.310638801724303, y2=0.2974609606193774), conf=0.8115234375, page_size=[1224, 1584], type='title', hidden=False, order=2, lang='en', direction=<Direction.Normal: -1>, source='', bboxes=[], contents=[], text='Abstract'),\n",
       " TextualResult(token='1a8888ee3e50585db98952c72834498e', page=0, block=3, bbox=BBox(x1=0.0792394338869581, y1=0.31132813655968866, x2=0.4676011528065002, y2=0.5347656481193773), conf=0.97802734375, page_size=[1224, 1584], type='paragraph', hidden=False, order=3, lang='en', direction=<Direction.Normal: -1>, source='', bboxes=[], contents=[], text='Deeper neural networks are more difﬁcult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classiﬁcation task. We also present analysis on CIFAR-10 with 100 and 1000 layers.'),\n",
       " TextualResult(token='1a8888ee3e50585db98952c72834498e', page=0, block=7, bbox=BBox(x1=0.07734375373989928, y1=0.5375000154129183, x2=0.4681066375931883, y2=0.65625), conf=0.96923828125, page_size=[1224, 1584], type='paragraph', hidden=False, order=4, lang='en', direction=<Direction.Normal: -1>, source='', bboxes=[], contents=[], text='The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28% relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_dict[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1347b849",
   "metadata": {},
   "source": [
    "#### - Pages tree 格式输出\n",
    "> Uni-Parser 的原始解析格式，比pages dict更加复杂，是带有嵌套关系的树结构\n",
    "> \n",
    "> 未经过任何format化，返回内容为json格式的全文语义块，可以用于后续的语义分析等场景\n",
    "> \n",
    "> 内容详尽充分，但是格式复杂，需要自行解析，可以自行 重排序 、去重 等操作，是高阶玩法必备\n",
    ">\n",
    "> 目前40001端口不支持，放在advance中介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e2bcf",
   "metadata": {},
   "source": [
    "## 2. 图片文件解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d3c4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置解析文件路径\n",
    "snip_path = \"./tasks/0711.2032v1_page20.png\"\n",
    "\n",
    "# 提交解析任务\n",
    "trigger_snip_result = parser.trigger_snip(\n",
    "    snip_path,\n",
    "    textual=ParseModeTextual.OCRFast,\n",
    "    table=ParseMode.OCRFast,\n",
    "    molecule=ParseMode.OCRFast,\n",
    "    chart=ParseMode.DumpBase64,\n",
    "    figure=ParseMode.DumpBase64,\n",
    "    expression=ParseMode.DumpBase64,\n",
    "    equation=ParseMode.OCRFast,\n",
    ")\n",
    "if trigger_snip_result[\"status\"] != \"success\":\n",
    "    print(json.dumps(trigger_snip_result, indent=4))\n",
    "    raise Exception(\"trigger file failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c8d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务提交成功后，会返回一个token，用于获取解析结果\n",
    "assert trigger_snip_result[\"status\"] == \"success\"\n",
    "token = trigger_snip_result[\"token\"]\n",
    "for formatted in list(FormatFlag)[1:]:\n",
    "    # content must be True\n",
    "    # formatted 只对objects和content产生作用，pages_dict和pages_tree不受影响\n",
    "    result = parser.get_formatted(\n",
    "        token,\n",
    "        content=True,\n",
    "        objects=False,\n",
    "        pages_dict=False,\n",
    "        pages_tree=False,\n",
    "        molecule_source=False,\n",
    "        textual=formatted,\n",
    "        chart=formatted,\n",
    "        table=formatted,\n",
    "        molecule=formatted,\n",
    "        equation=formatted,\n",
    "        figure=formatted,\n",
    "        expression=formatted,\n",
    "    )\n",
    "    if result[\"status\"] != \"success\":\n",
    "        print(f\"Get formatted failed for {formatted}, results is: {json.dumps(result, indent=4)}\")\n",
    "        continue\n",
    "\n",
    "    head, tail = \"\", \"\"\n",
    "    suffix = \"\"\n",
    "    if formatted == \"latex\":\n",
    "        head = \"\\documentclass{article}\\n\\n\\\\usepackage{booktabs}\\n\\n\\\\begin{document}\\n\"\n",
    "        tail = \"\\end{document}\"\n",
    "        suffix = \"tex\"\n",
    "    elif formatted == \"html\":\n",
    "        head = \"<html>\\n\\n<body>\\n\"\n",
    "        tail = \"</body>\\n\\n</html>\"\n",
    "        suffix = \"html\"\n",
    "    elif formatted == \"markdown\":\n",
    "        suffix = \"md\"\n",
    "    elif formatted == \"plain\":\n",
    "        suffix = \"plain\"\n",
    "    elif formatted == \"markup\":\n",
    "        suffix = \"txt\"\n",
    "    else:\n",
    "        print(f\"Unknown format: {formatted}\")\n",
    "        continue\n",
    "\n",
    "    with open(f\"{save_dir}/{token}.{suffix}\", \"w\") as f:\n",
    "        if head:\n",
    "            f.write(head + \"\\n\")\n",
    "        try:\n",
    "            f.write(result[\"content\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "        if tail:\n",
    "            f.write(tail + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c42477",
   "metadata": {},
   "source": [
    "## 3. PDF URL 解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0115c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置解析文件url 【外网pdf可能会出现网络问题，不建议，必要时可以设置proxy】\n",
    "pdf_url = \"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\"\n",
    "\n",
    "\n",
    "# 提交解析任务\n",
    "trigger_url_result = parser.trigger_url(\n",
    "    pdf_url,\n",
    "    textual=ParseModeTextual.OCRFast,\n",
    "    table=ParseMode.OCRFast,\n",
    "    molecule=ParseMode.OCRFast,\n",
    "    chart=ParseMode.DumpBase64,\n",
    "    figure=ParseMode.DumpBase64,\n",
    "    expression=ParseMode.DumpBase64,\n",
    "    equation=ParseMode.OCRFast,\n",
    "    proxy=None,\n",
    ")\n",
    "if trigger_url_result[\"status\"] != \"success\":\n",
    "    print(json.dumps(trigger_url_result, indent=4))\n",
    "    print(trigger_url_result['traceback'])\n",
    "    raise Exception(\"trigger file failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "631d81c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任务提交成功后，会返回一个token，用于获取解析结果\n",
    "assert trigger_url_result[\"status\"] == \"success\"\n",
    "token = trigger_url_result[\"token\"]\n",
    "for formatted in list(FormatFlag)[1:]:\n",
    "    # content must be True\n",
    "    # formatted 只对objects和content产生作用，pages_dict和pages_tree不受影响\n",
    "    result = parser.get_formatted(\n",
    "        token,\n",
    "        content=True,\n",
    "        objects=False,\n",
    "        pages_dict=False,\n",
    "        pages_tree=False,\n",
    "        molecule_source=False,\n",
    "        textual=formatted,\n",
    "        chart=formatted,\n",
    "        table=formatted,\n",
    "        molecule=formatted,\n",
    "        equation=formatted,\n",
    "        figure=formatted,\n",
    "        expression=formatted,\n",
    "    )\n",
    "    if result[\"status\"] != \"success\":\n",
    "        print(f\"Get formatted failed for {formatted}, results is: {json.dumps(result, indent=4)}\")\n",
    "        continue\n",
    "\n",
    "    head, tail = \"\", \"\"\n",
    "    suffix = \"\"\n",
    "    if formatted == \"latex\":\n",
    "        head = \"\\documentclass{article}\\n\\n\\\\usepackage{booktabs}\\n\\n\\\\begin{document}\\n\"\n",
    "        tail = \"\\end{document}\"\n",
    "        suffix = \"tex\"\n",
    "    elif formatted == \"html\":\n",
    "        head = \"<html>\\n\\n<body>\\n\"\n",
    "        tail = \"</body>\\n\\n</html>\"\n",
    "        suffix = \"html\"\n",
    "    elif formatted == \"markdown\":\n",
    "        suffix = \"md\"\n",
    "    elif formatted == \"plain\":\n",
    "        suffix = \"plain\"\n",
    "    elif formatted == \"markup\":\n",
    "        suffix = \"txt\"\n",
    "    else:\n",
    "        print(f\"Unknown format: {formatted}\")\n",
    "        continue\n",
    "\n",
    "    with open(f\"{save_dir}/{token}.{suffix}\", \"w\") as f:\n",
    "        if head:\n",
    "            f.write(head + \"\\n\")\n",
    "        try:\n",
    "            f.write(result[\"content\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "        if tail:\n",
    "            f.write(tail + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99b0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniparser-tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
